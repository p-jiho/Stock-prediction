{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a2fddb-a95e-4e07-8c18-f925480e643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stock price prediction using BERT and GAN, 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a497af73-7bd6-47cc-bcfc-0f5afaf295a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "\n",
    "import random\n",
    "import train_test as tt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db2d3be7-943b-4cad-a8aa-7c21090a0e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100 \n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2930d510-4551-469a-ba3d-56ff90ce5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52f8f422-a447-4397-a962-679f223148a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### 논문 재현(변수 다르고, APPLE 사용) #######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7067b3dd-9aa7-494f-bfcb-878dbd2d829c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whfhrs3260/Python/10year_data/review/train_test.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  set_news_data_date.price_date[i]=standard  + datetime.timedelta(days=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whfhrs3260/Python/10year_data/review/train_test.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price_data.before_close[i+1] = price_data.Close[i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "23/23 [==============================] - 2s 23ms/step - loss: 0.0044 - val_loss: 0.0011\n",
      "Epoch 2/150\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 5.2130e-04 - val_loss: 1.6892e-04\n",
      "Epoch 3/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 7.8312e-05 - val_loss: 2.8532e-05\n",
      "Epoch 4/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.5005e-05 - val_loss: 2.5149e-05\n",
      "Epoch 5/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9687e-05 - val_loss: 3.2435e-05\n",
      "Epoch 6/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9943e-05 - val_loss: 3.5820e-05\n",
      "Epoch 7/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9957e-05 - val_loss: 2.7917e-05\n",
      "Epoch 8/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9794e-05 - val_loss: 3.7090e-05\n",
      "Epoch 9/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0728e-05 - val_loss: 2.6214e-05\n",
      "Epoch 10/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.1186e-05 - val_loss: 3.0715e-05\n",
      "Epoch 11/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.2393e-05 - val_loss: 3.4233e-05\n",
      "Epoch 12/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9896e-05 - val_loss: 2.5280e-05\n",
      "Epoch 13/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.2365e-05 - val_loss: 2.8120e-05\n",
      "Epoch 14/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0989e-05 - val_loss: 2.7867e-05\n",
      "Epoch 15/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9871e-05 - val_loss: 3.1592e-05\n",
      "Epoch 16/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0513e-05 - val_loss: 2.5520e-05\n",
      "Epoch 17/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9505e-05 - val_loss: 3.0410e-05\n",
      "Epoch 18/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0061e-05 - val_loss: 2.3534e-05\n",
      "Epoch 19/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0323e-05 - val_loss: 3.4623e-05\n",
      "Epoch 20/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.6150e-05 - val_loss: 4.8383e-05\n",
      "Epoch 21/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0243e-05 - val_loss: 2.3282e-05\n",
      "Epoch 22/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9741e-05 - val_loss: 2.4354e-05\n",
      "Epoch 23/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.2522e-05 - val_loss: 2.4924e-05\n",
      "Epoch 24/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9666e-05 - val_loss: 3.4489e-05\n",
      "Epoch 25/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0894e-05 - val_loss: 2.6303e-05\n",
      "Epoch 26/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.3220e-05 - val_loss: 2.8928e-05\n",
      "Epoch 27/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.1609e-05 - val_loss: 2.3326e-05\n",
      "Epoch 28/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0320e-05 - val_loss: 2.4353e-05\n",
      "Epoch 29/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.0303e-05 - val_loss: 2.4813e-05\n",
      "Epoch 30/150\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 2.9875e-05 - val_loss: 2.4811e-05\n",
      "Epoch 31/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.1713e-05 - val_loss: 5.4822e-05\n",
      "Epoch 32/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.1980e-05 - val_loss: 4.1232e-05\n",
      "Epoch 33/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9987e-05 - val_loss: 2.8829e-05\n",
      "Epoch 34/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.1317e-05 - val_loss: 2.3129e-05\n",
      "Epoch 35/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.2273e-05 - val_loss: 2.4255e-05\n",
      "Epoch 36/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0182e-05 - val_loss: 2.6061e-05\n",
      "Epoch 37/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0188e-05 - val_loss: 3.3392e-05\n",
      "Epoch 38/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0856e-05 - val_loss: 2.3186e-05\n",
      "Epoch 39/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9817e-05 - val_loss: 2.5578e-05\n",
      "Epoch 40/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9057e-05 - val_loss: 2.3080e-05\n",
      "Epoch 41/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0697e-05 - val_loss: 2.2321e-05\n",
      "Epoch 42/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0096e-05 - val_loss: 2.6157e-05\n",
      "Epoch 43/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0565e-05 - val_loss: 4.7017e-05\n",
      "Epoch 44/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.1234e-05 - val_loss: 2.5066e-05\n",
      "Epoch 45/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.2005e-05 - val_loss: 4.1835e-05\n",
      "Epoch 46/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.1185e-05 - val_loss: 2.3304e-05\n",
      "Epoch 47/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9796e-05 - val_loss: 2.2541e-05\n",
      "Epoch 48/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.0305e-05 - val_loss: 2.2919e-05\n",
      "Epoch 49/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.1637e-05 - val_loss: 4.2274e-05\n",
      "Epoch 50/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.2186e-05 - val_loss: 2.9229e-05\n",
      "Epoch 51/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.6881e-05 - val_loss: 2.7848e-05\n",
      "Epoch 52/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.2543e-05 - val_loss: 3.2682e-05\n",
      "Epoch 53/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9641e-05 - val_loss: 2.7243e-05\n",
      "Epoch 54/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.0524e-05 - val_loss: 2.5637e-05\n",
      "Epoch 55/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.4181e-05 - val_loss: 5.1614e-05\n",
      "Epoch 56/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.5479e-05 - val_loss: 3.0058e-05\n",
      "Epoch 57/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.1524e-05 - val_loss: 3.0329e-05\n",
      "Epoch 58/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0269e-05 - val_loss: 2.5457e-05\n",
      "Epoch 59/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9948e-05 - val_loss: 4.4801e-05\n",
      "Epoch 60/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.2227e-05 - val_loss: 2.2593e-05\n",
      "Epoch 61/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9066e-05 - val_loss: 2.1767e-05\n",
      "Epoch 62/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0796e-05 - val_loss: 2.1335e-05\n",
      "Epoch 63/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.1642e-05 - val_loss: 2.2750e-05\n",
      "Epoch 64/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.2835e-05 - val_loss: 3.6756e-05\n",
      "Epoch 65/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.1347e-05 - val_loss: 3.2605e-05\n",
      "Epoch 66/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0872e-05 - val_loss: 5.1164e-05\n",
      "Epoch 67/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0321e-05 - val_loss: 2.2389e-05\n",
      "Epoch 68/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.4954e-05 - val_loss: 2.3991e-05\n",
      "Epoch 69/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9867e-05 - val_loss: 3.1230e-05\n",
      "Epoch 70/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.0759e-05 - val_loss: 3.4699e-05\n",
      "Epoch 71/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.4368e-05 - val_loss: 2.8370e-05\n",
      "Epoch 72/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.1483e-05 - val_loss: 3.8612e-05\n",
      "Epoch 73/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9820e-05 - val_loss: 2.1373e-05\n",
      "Epoch 74/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 1.9712e-05 - val_loss: 2.4267e-05\n",
      "Epoch 75/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0461e-05 - val_loss: 2.3492e-05\n",
      "Epoch 76/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.1740e-05 - val_loss: 2.1259e-05\n",
      "Epoch 77/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.3454e-05 - val_loss: 3.4036e-05\n",
      "Epoch 78/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.3660e-05 - val_loss: 2.8541e-05\n",
      "Epoch 79/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0826e-05 - val_loss: 2.4248e-05\n",
      "Epoch 80/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.2048e-05 - val_loss: 2.7153e-05\n",
      "Epoch 81/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.1434e-05 - val_loss: 2.8154e-05\n",
      "Epoch 82/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.1449e-05 - val_loss: 2.5521e-05\n",
      "Epoch 83/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.8301e-05 - val_loss: 3.7824e-05\n",
      "Epoch 84/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.1561e-05 - val_loss: 2.3714e-05\n",
      "Epoch 85/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.6395e-05 - val_loss: 2.1521e-05\n",
      "Epoch 86/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.4425e-05 - val_loss: 2.1856e-05\n",
      "Epoch 87/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.2257e-05 - val_loss: 2.4859e-05\n",
      "Epoch 88/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9563e-05 - val_loss: 2.0410e-05\n",
      "Epoch 89/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.1293e-05 - val_loss: 2.1170e-05\n",
      "Epoch 90/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9929e-05 - val_loss: 2.3538e-05\n",
      "Epoch 91/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9485e-05 - val_loss: 2.3080e-05\n",
      "Epoch 92/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.7416e-05 - val_loss: 2.4449e-05\n",
      "Epoch 93/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0048e-05 - val_loss: 2.2977e-05\n",
      "Epoch 94/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0509e-05 - val_loss: 2.7122e-05\n",
      "Epoch 95/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.8965e-05 - val_loss: 1.9686e-05\n",
      "Epoch 96/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.7605e-05 - val_loss: 4.0225e-05\n",
      "Epoch 97/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.3877e-05 - val_loss: 5.6025e-05\n",
      "Epoch 98/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.4318e-05 - val_loss: 2.0917e-05\n",
      "Epoch 99/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.8644e-05 - val_loss: 2.0232e-05\n",
      "Epoch 100/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.2531e-05 - val_loss: 1.9570e-05\n",
      "Epoch 101/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.4297e-05 - val_loss: 2.1934e-05\n",
      "Epoch 102/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 1.9793e-05 - val_loss: 1.9019e-05\n",
      "Epoch 103/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.7240e-05 - val_loss: 2.0164e-05\n",
      "Epoch 104/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9664e-05 - val_loss: 2.5047e-05\n",
      "Epoch 105/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.7587e-05 - val_loss: 2.0012e-05\n",
      "Epoch 106/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0352e-05 - val_loss: 2.0069e-05\n",
      "Epoch 107/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.1647e-05 - val_loss: 2.4540e-05\n",
      "Epoch 108/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.8892e-05 - val_loss: 2.6452e-05\n",
      "Epoch 109/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.2384e-05 - val_loss: 4.3351e-05\n",
      "Epoch 110/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.2973e-05 - val_loss: 2.8943e-05\n",
      "Epoch 111/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.8476e-05 - val_loss: 4.3633e-05\n",
      "Epoch 112/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.8284e-05 - val_loss: 1.9717e-05\n",
      "Epoch 113/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 1.7808e-05 - val_loss: 2.0645e-05\n",
      "Epoch 114/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 1.8397e-05 - val_loss: 3.3109e-05\n",
      "Epoch 115/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.7571e-05 - val_loss: 2.2392e-05\n",
      "Epoch 116/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0485e-05 - val_loss: 2.0305e-05\n",
      "Epoch 117/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.8456e-05 - val_loss: 2.1728e-05\n",
      "Epoch 118/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9775e-05 - val_loss: 3.6324e-05\n",
      "Epoch 119/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.3526e-05 - val_loss: 1.9319e-05\n",
      "Epoch 120/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.1353e-05 - val_loss: 3.5768e-05\n",
      "Epoch 121/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.8942e-05 - val_loss: 2.4854e-05\n",
      "Epoch 122/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.7075e-05 - val_loss: 2.6945e-05\n",
      "Epoch 123/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.7074e-05 - val_loss: 2.1167e-05\n",
      "Epoch 124/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.8434e-05 - val_loss: 2.1695e-05\n",
      "Epoch 125/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.6745e-05 - val_loss: 3.1966e-05\n",
      "Epoch 126/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 1.8297e-05 - val_loss: 1.8272e-05\n",
      "Epoch 127/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.0237e-05 - val_loss: 2.1602e-05\n",
      "Epoch 128/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.3198e-05 - val_loss: 2.2423e-05\n",
      "Epoch 129/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.8676e-05 - val_loss: 2.9668e-05\n",
      "Epoch 130/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 1.6352e-05 - val_loss: 4.7986e-05\n",
      "Epoch 131/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.7744e-05 - val_loss: 2.4177e-05\n",
      "Epoch 132/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.6859e-05 - val_loss: 2.5439e-05\n",
      "Epoch 133/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.7432e-05 - val_loss: 2.2018e-05\n",
      "Epoch 134/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.8909e-05 - val_loss: 2.9139e-05\n",
      "Epoch 135/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.6680e-05 - val_loss: 3.1359e-05\n",
      "Epoch 136/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.7263e-05 - val_loss: 1.8785e-05\n",
      "Epoch 137/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.8272e-05 - val_loss: 2.1094e-05\n",
      "Epoch 138/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.6558e-05 - val_loss: 1.7618e-05\n",
      "Epoch 139/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.7919e-05 - val_loss: 3.0314e-05\n",
      "Epoch 140/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.9302e-05 - val_loss: 2.0744e-05\n",
      "Epoch 141/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.6218e-05 - val_loss: 2.0573e-05\n",
      "Epoch 142/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0125e-05 - val_loss: 5.7092e-05\n",
      "Epoch 143/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.7550e-05 - val_loss: 2.4848e-05\n",
      "Epoch 144/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.6501e-05 - val_loss: 1.6944e-05\n",
      "Epoch 145/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.6211e-05 - val_loss: 1.8812e-05\n",
      "Epoch 146/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.7223e-05 - val_loss: 2.2869e-05\n",
      "Epoch 147/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.0674e-05 - val_loss: 1.7008e-05\n",
      "Epoch 148/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.3618e-05 - val_loss: 1.8581e-05\n",
      "Epoch 149/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.7606e-05 - val_loss: 2.0318e-05\n",
      "Epoch 150/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 1.6112e-05 - val_loss: 4.2984e-05\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0025\n"
     ]
    }
   ],
   "source": [
    "dir = \"/home/whfhrs3260/csv_data/price_data_score_10years.csv\"\n",
    "stock = \"AAPL\"\n",
    "variable = [\"before_close\",\"Score\"]\n",
    "window_size = 3\n",
    "start_date = \"2010-07-01\"\n",
    "end_date = \"2020-07-31\"\n",
    "\n",
    "scaler_x, scaler_y,x, y, x_t, y_t = tt.train_test_result(dir, stock, variable, window_size, start_date, end_date)\n",
    "\n",
    "lstm_1_model = Sequential()\n",
    "lstm_1_model.add(LSTM(128, input_shape = (x.shape[1],x.shape[2])))\n",
    "lstm_1_model.add(Dense(64))\n",
    "lstm_1_model.add(Dense(1,activation=\"tanh\"))\n",
    "adam = optimizers.Adam(learning_rate=0.0012)\n",
    "lstm_1_model.compile(optimizer=adam, loss = \"mse\")\n",
    "history = lstm_1_model.fit(x, y, epochs=150, batch_size=64, validation_split=0.2)\n",
    "    \n",
    "lstm_1_pred = lstm_1_model.evaluate(x_t, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34bb1906-9ca6-4b25-9f6d-c0d712e3e933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float64, numpy=4.888956048629097>,\n",
       " 23.90189124542703,\n",
       " 3.323381629743074,\n",
       " 5.212607150938138)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_1_pred = lstm_1_model.predict(x_t)\n",
    "lstm_1_pred = scaler_y.inverse_transform(lstm_1_pred)\n",
    "y_t = scaler_y.inverse_transform(y_t)\n",
    "root_mean_squared_error(y_t, lstm_1_pred), mean_squared_error(y_t, lstm_1_pred), mean_absolute_error(y_t, lstm_1_pred), MAPE(y_t, lstm_1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae9c175-e632-468c-a030-96204257bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### 2 variable(news, close 사용) #####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a77e7ca0-e8c6-4307-ab12-f4a95320f3ba",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whfhrs3260/Python/10year_data/review/train_test.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  set_news_data_date.price_date[i]=standard  + datetime.timedelta(days=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whfhrs3260/Python/10year_data/review/train_test.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price_data.before_close[i+1] = price_data.Close[i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "23/23 [==============================] - 2s 24ms/step - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 2/150\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 7.0805e-04 - val_loss: 9.7312e-04\n",
      "Epoch 3/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 1.6618e-04 - val_loss: 0.0020\n",
      "Epoch 4/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 9.6280e-05 - val_loss: 9.4153e-04\n",
      "Epoch 5/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 6.5872e-05 - val_loss: 9.4320e-04\n",
      "Epoch 6/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 5.2593e-05 - val_loss: 7.4243e-04\n",
      "Epoch 7/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.6712e-05 - val_loss: 6.0975e-04\n",
      "Epoch 8/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.4098e-05 - val_loss: 5.8363e-04\n",
      "Epoch 9/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.4005e-05 - val_loss: 6.3410e-04\n",
      "Epoch 10/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.1156e-05 - val_loss: 4.5168e-04\n",
      "Epoch 11/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.2158e-05 - val_loss: 4.7026e-04\n",
      "Epoch 12/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.0838e-05 - val_loss: 4.1295e-04\n",
      "Epoch 13/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.0666e-05 - val_loss: 4.9102e-04\n",
      "Epoch 14/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.0398e-05 - val_loss: 3.7737e-04\n",
      "Epoch 15/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.1355e-05 - val_loss: 3.5658e-04\n",
      "Epoch 16/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 4.2701e-05 - val_loss: 3.4311e-04\n",
      "Epoch 17/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 4.0641e-05 - val_loss: 3.5799e-04\n",
      "Epoch 18/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 4.0321e-05 - val_loss: 3.8881e-04\n",
      "Epoch 19/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 4.1050e-05 - val_loss: 3.1775e-04\n",
      "Epoch 20/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.1015e-05 - val_loss: 3.7138e-04\n",
      "Epoch 21/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.1576e-05 - val_loss: 3.2706e-04\n",
      "Epoch 22/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.8844e-05 - val_loss: 3.5082e-04\n",
      "Epoch 23/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.9736e-05 - val_loss: 3.1590e-04\n",
      "Epoch 24/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.8838e-05 - val_loss: 2.8390e-04\n",
      "Epoch 25/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.8256e-05 - val_loss: 2.6286e-04\n",
      "Epoch 26/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.8028e-05 - val_loss: 3.2508e-04\n",
      "Epoch 27/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.0260e-05 - val_loss: 3.3197e-04\n",
      "Epoch 28/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.8100e-05 - val_loss: 4.1597e-04\n",
      "Epoch 29/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 4.0305e-05 - val_loss: 2.6798e-04\n",
      "Epoch 30/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.0248e-05 - val_loss: 4.0350e-04\n",
      "Epoch 31/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.4233e-05 - val_loss: 2.5648e-04\n",
      "Epoch 32/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.9438e-05 - val_loss: 3.0087e-04\n",
      "Epoch 33/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.8854e-05 - val_loss: 3.0863e-04\n",
      "Epoch 34/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.8381e-05 - val_loss: 2.0640e-04\n",
      "Epoch 35/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.0308e-05 - val_loss: 3.0412e-04\n",
      "Epoch 36/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 4.2440e-05 - val_loss: 3.2011e-04\n",
      "Epoch 37/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 4.5426e-05 - val_loss: 2.5435e-04\n",
      "Epoch 38/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.9660e-05 - val_loss: 3.7525e-04\n",
      "Epoch 39/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.2487e-05 - val_loss: 3.7668e-04\n",
      "Epoch 40/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.8917e-05 - val_loss: 2.3710e-04\n",
      "Epoch 41/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.7829e-05 - val_loss: 2.0573e-04\n",
      "Epoch 42/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 4.0238e-05 - val_loss: 3.2060e-04\n",
      "Epoch 43/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.7328e-05 - val_loss: 2.1577e-04\n",
      "Epoch 44/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.9733e-05 - val_loss: 2.3840e-04\n",
      "Epoch 45/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.0204e-05 - val_loss: 2.6670e-04\n",
      "Epoch 46/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.7924e-05 - val_loss: 2.1717e-04\n",
      "Epoch 47/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.8315e-05 - val_loss: 2.2293e-04\n",
      "Epoch 48/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.9940e-05 - val_loss: 2.5058e-04\n",
      "Epoch 49/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.1239e-05 - val_loss: 3.1036e-04\n",
      "Epoch 50/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.7950e-05 - val_loss: 2.9791e-04\n",
      "Epoch 51/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.1770e-05 - val_loss: 2.6902e-04\n",
      "Epoch 52/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.8428e-05 - val_loss: 2.1662e-04\n",
      "Epoch 53/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.7815e-05 - val_loss: 1.9995e-04\n",
      "Epoch 54/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.7390e-05 - val_loss: 2.4521e-04\n",
      "Epoch 55/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.8312e-05 - val_loss: 1.5947e-04\n",
      "Epoch 56/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.4656e-05 - val_loss: 2.4585e-04\n",
      "Epoch 57/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.9248e-05 - val_loss: 1.9613e-04\n",
      "Epoch 58/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.1145e-05 - val_loss: 2.8880e-04\n",
      "Epoch 59/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.8392e-05 - val_loss: 2.2997e-04\n",
      "Epoch 60/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.7629e-05 - val_loss: 2.9481e-04\n",
      "Epoch 61/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.2437e-05 - val_loss: 1.7574e-04\n",
      "Epoch 62/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.7755e-05 - val_loss: 3.0518e-04\n",
      "Epoch 63/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.9064e-05 - val_loss: 2.4397e-04\n",
      "Epoch 64/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.5716e-05 - val_loss: 2.6079e-04\n",
      "Epoch 65/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.1759e-05 - val_loss: 2.4398e-04\n",
      "Epoch 66/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.4254e-05 - val_loss: 2.8345e-04\n",
      "Epoch 67/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.7703e-05 - val_loss: 2.5945e-04\n",
      "Epoch 68/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.8933e-05 - val_loss: 3.4255e-04\n",
      "Epoch 69/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.6840e-05 - val_loss: 2.3999e-04\n",
      "Epoch 70/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.7274e-05 - val_loss: 2.8956e-04\n",
      "Epoch 71/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.7275e-05 - val_loss: 2.1287e-04\n",
      "Epoch 72/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.7547e-05 - val_loss: 2.7334e-04\n",
      "Epoch 73/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.8649e-05 - val_loss: 1.7882e-04\n",
      "Epoch 74/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.6642e-05 - val_loss: 3.2687e-04\n",
      "Epoch 75/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.5539e-05 - val_loss: 1.8057e-04\n",
      "Epoch 76/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.6966e-05 - val_loss: 1.8696e-04\n",
      "Epoch 77/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.5919e-05 - val_loss: 1.6248e-04\n",
      "Epoch 78/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.1873e-05 - val_loss: 1.9166e-04\n",
      "Epoch 79/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.6421e-05 - val_loss: 1.9039e-04\n",
      "Epoch 80/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.6664e-05 - val_loss: 2.2819e-04\n",
      "Epoch 81/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.0630e-05 - val_loss: 4.0217e-04\n",
      "Epoch 82/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.7145e-05 - val_loss: 4.4620e-04\n",
      "Epoch 83/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.1519e-05 - val_loss: 1.9165e-04\n",
      "Epoch 84/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.6059e-05 - val_loss: 2.4011e-04\n",
      "Epoch 85/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.3288e-05 - val_loss: 1.9236e-04\n",
      "Epoch 86/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.6855e-05 - val_loss: 1.4692e-04\n",
      "Epoch 87/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.9467e-05 - val_loss: 2.1463e-04\n",
      "Epoch 88/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.6952e-05 - val_loss: 2.0306e-04\n",
      "Epoch 89/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.4972e-05 - val_loss: 2.4334e-04\n",
      "Epoch 90/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.1357e-05 - val_loss: 2.3484e-04\n",
      "Epoch 91/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.3996e-05 - val_loss: 2.9877e-04\n",
      "Epoch 92/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.5692e-05 - val_loss: 1.4953e-04\n",
      "Epoch 93/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.7221e-05 - val_loss: 2.2860e-04\n",
      "Epoch 94/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.5028e-05 - val_loss: 2.1900e-04\n",
      "Epoch 95/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.4340e-05 - val_loss: 2.3923e-04\n",
      "Epoch 96/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.0652e-05 - val_loss: 1.5251e-04\n",
      "Epoch 97/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.5423e-05 - val_loss: 2.1843e-04\n",
      "Epoch 98/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.6147e-05 - val_loss: 1.7454e-04\n",
      "Epoch 99/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.6540e-05 - val_loss: 2.9997e-04\n",
      "Epoch 100/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.2212e-05 - val_loss: 2.8412e-04\n",
      "Epoch 101/150\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 4.5450e-05 - val_loss: 3.0380e-04\n",
      "Epoch 102/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.2136e-05 - val_loss: 1.9271e-04\n",
      "Epoch 103/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.6744e-05 - val_loss: 2.3063e-04\n",
      "Epoch 104/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.3890e-05 - val_loss: 2.2590e-04\n",
      "Epoch 105/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.5191e-05 - val_loss: 2.3399e-04\n",
      "Epoch 106/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.9268e-05 - val_loss: 2.8044e-04\n",
      "Epoch 107/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.2192e-05 - val_loss: 2.0776e-04\n",
      "Epoch 108/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.3806e-05 - val_loss: 2.6608e-04\n",
      "Epoch 109/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.0691e-05 - val_loss: 3.5865e-04\n",
      "Epoch 110/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.0586e-05 - val_loss: 2.4866e-04\n",
      "Epoch 111/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.4304e-05 - val_loss: 2.3289e-04\n",
      "Epoch 112/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.8684e-05 - val_loss: 1.6095e-04\n",
      "Epoch 113/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.3170e-05 - val_loss: 3.2546e-04\n",
      "Epoch 114/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.6647e-05 - val_loss: 3.1181e-04\n",
      "Epoch 115/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.7874e-05 - val_loss: 2.2335e-04\n",
      "Epoch 116/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.9038e-05 - val_loss: 2.1750e-04\n",
      "Epoch 117/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.8252e-05 - val_loss: 1.5634e-04\n",
      "Epoch 118/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.7862e-05 - val_loss: 2.1378e-04\n",
      "Epoch 119/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.3456e-05 - val_loss: 2.6628e-04\n",
      "Epoch 120/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.2795e-05 - val_loss: 2.1336e-04\n",
      "Epoch 121/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.3391e-05 - val_loss: 2.6093e-04\n",
      "Epoch 122/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.1035e-05 - val_loss: 2.4362e-04\n",
      "Epoch 123/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.5866e-05 - val_loss: 3.3862e-04\n",
      "Epoch 124/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.0334e-05 - val_loss: 2.1530e-04\n",
      "Epoch 125/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.1742e-05 - val_loss: 1.6887e-04\n",
      "Epoch 126/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.7796e-05 - val_loss: 1.8872e-04\n",
      "Epoch 127/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.3854e-05 - val_loss: 1.6438e-04\n",
      "Epoch 128/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.0411e-05 - val_loss: 2.0914e-04\n",
      "Epoch 129/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.3027e-05 - val_loss: 2.0853e-04\n",
      "Epoch 130/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.1862e-05 - val_loss: 1.7523e-04\n",
      "Epoch 131/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.2272e-05 - val_loss: 2.3879e-04\n",
      "Epoch 132/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.2119e-05 - val_loss: 1.3932e-04\n",
      "Epoch 133/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.2798e-05 - val_loss: 2.9959e-04\n",
      "Epoch 134/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.3059e-05 - val_loss: 2.4903e-04\n",
      "Epoch 135/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.3317e-05 - val_loss: 2.7812e-04\n",
      "Epoch 136/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.6565e-05 - val_loss: 2.7041e-04\n",
      "Epoch 137/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.2517e-05 - val_loss: 2.1446e-04\n",
      "Epoch 138/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.9475e-05 - val_loss: 2.9255e-04\n",
      "Epoch 139/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.7227e-05 - val_loss: 3.2830e-04\n",
      "Epoch 140/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.6907e-05 - val_loss: 3.2377e-04\n",
      "Epoch 141/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 4.0727e-05 - val_loss: 3.0431e-04\n",
      "Epoch 142/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 4.1588e-05 - val_loss: 1.9324e-04\n",
      "Epoch 143/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.4209e-05 - val_loss: 2.3496e-04\n",
      "Epoch 144/150\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 3.1695e-05 - val_loss: 1.8233e-04\n",
      "Epoch 145/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.0505e-05 - val_loss: 2.0549e-04\n",
      "Epoch 146/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.6333e-05 - val_loss: 1.6669e-04\n",
      "Epoch 147/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.7690e-05 - val_loss: 1.6904e-04\n",
      "Epoch 148/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.2171e-05 - val_loss: 2.0591e-04\n",
      "Epoch 149/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 3.0038e-05 - val_loss: 1.8533e-04\n",
      "Epoch 150/150\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 2.8416e-05 - val_loss: 1.9315e-04\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0064\n"
     ]
    }
   ],
   "source": [
    "dir = \"/home/whfhrs3260/csv_data/price_data_score_10years.csv\"\n",
    "stock = \"^DJI\"\n",
    "variable = [\"before_close\",\"Score\"]\n",
    "window_size = 3\n",
    "start_date = \"2012-01-01\"\n",
    "end_date = \"2022-04-30\"\n",
    "\n",
    "scaler_x, scaler_y,x, y, x_t, y_t = tt.train_test_result(dir, stock, variable, window_size, start_date, end_date)\n",
    "\n",
    "lstm_1_model = Sequential()\n",
    "lstm_1_model.add(LSTM(128, input_shape = (x.shape[1],x.shape[2])))\n",
    "lstm_1_model.add(Dense(64))\n",
    "lstm_1_model.add(Dense(1,activation=\"tanh\"))\n",
    "adam = optimizers.Adam(learning_rate=0.0012)\n",
    "lstm_1_model.compile(optimizer=adam, loss = \"mse\")\n",
    "history = lstm_1_model.fit(x, y, epochs=150, batch_size=64, validation_split=0.2)\n",
    "    \n",
    "lstm_1_pred = lstm_1_model.evaluate(x_t, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f67cc84c-2acc-4913-9c4a-117d42c76775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float64, numpy=1978.6404844792078>,\n",
       " 3915018.1668201145,\n",
       " 1573.587303181234,\n",
       " 4.856514488232598)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_1_pred = lstm_1_model.predict(x_t)\n",
    "lstm_1_pred = scaler_y.inverse_transform(lstm_1_pred)\n",
    "y_t = scaler_y.inverse_transform(y_t)\n",
    "root_mean_squared_error(y_t, lstm_1_pred), mean_squared_error(y_t, lstm_1_pred), mean_absolute_error(y_t, lstm_1_pred), MAPE(y_t, lstm_1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afc3b279-aa5f-481b-be08-05fc307f0039",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_model = \"/home/whfhrs3260/model/\"\n",
    "#lstm_1_model.save(dir_model + 'lstm_128_64_window30_10years.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a6ec52-2cb0-4400-ac8e-e5326af29039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec9878d-8b10-43c6-a1bb-c86de30685ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363a03f6-a41b-4cd3-b91a-e520b794e1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860b8aa9-03e3-4fc2-987b-efb947f1ca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b394a857-4a55-4339-aff1-772814641f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c11fadad-5649-4d21-924e-1964f4f6e8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whfhrs3260/Python/10year_data/review/train_test.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  set_news_data_date.price_date[i]=standard  + datetime.timedelta(days=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whfhrs3260/Python/10year_data/review/train_test.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price_data.before_close[i+1] = price_data.Close[i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 17ms/step\n",
      "24/24 [==============================] - 1s 17ms/step - loss: 0.0633 - mse: 0.0059 - mae: 0.0615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06333596259355545, 0.005902477074414492, 0.061517614871263504]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = \"/home/whfhrs3260/csv_data/price_data_score_10years.csv\"\n",
    "stock = \"^DJI\"\n",
    "variable = [\"before_close\",\"Score\"]\n",
    "window_size = 30\n",
    "start_date = \"2012-01-01\"\n",
    "end_date = \"2022-04-30\"\n",
    "\n",
    "scaler_x, scaler_y,x, y, x_t, y_t = tt.train_test_result(dir, stock, variable, window_size, start_date, end_date)\n",
    "lstm_1_model = load_model(dir_model + 'lstm_128_64_window30_10years.h5', custom_objects ={\"root_mean_squared_error\" : root_mean_squared_error})\n",
    "lstm_1_pred = lstm_1_model.predict(x_t)\n",
    "lstm_1_model.evaluate(x_t,y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4416591-9bb5-46cb-9ebf-7f01d5a99b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float64, numpy=1897.5016574779052>,\n",
       " 3600512.5401313975,\n",
       " 1519.3734083721704,\n",
       " 4.684872964432992)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_1_pred = scaler_y.inverse_transform(lstm_1_pred)\n",
    "y_t = scaler_y.inverse_transform(y_t)\n",
    "root_mean_squared_error(y_t, lstm_1_pred), mean_squared_error(y_t, lstm_1_pred), mean_absolute_error(y_t, lstm_1_pred), MAPE(y_t, lstm_1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a67cb42-b6ac-4c17-9148-bcec5990ef3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
