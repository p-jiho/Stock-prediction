{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e31b9776-4ae7-4202-8429-3ed89d42ab4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 15:00:03.621085: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-24 15:00:03.721837: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-24 15:00:03.724824: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-24 15:00:03.724838: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-24 15:00:04.269456: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-24 15:00:04.269520: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-24 15:00:04.269525: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import regex as re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import datetime\n",
    "\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(\"__file__\"))))\n",
    "import train_test as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c130ac5f-66bc-46dc-b1b8-d5aa0ea75910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100 \n",
    "    \n",
    "    \n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "    \n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "481d4a39-9f4a-4eb2-9a95-a77cffbb4941",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### 논문 재현(변수 다르고, Amazon 사용) #######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eafd18a7-e2f0-46fa-a592-a48b1ddc106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성, 처리\n",
    "def time_conversion(time):\n",
    "    time = pd.Timestamp(time)\n",
    "    return time\n",
    "\n",
    "def date_cut_day(dataframe_date_timestamp):\n",
    "    dataframe_date_timestamp = datetime.datetime.strftime(dataframe_date_timestamp, \"%Y-%m-%d\")\n",
    "    return dataframe_date_timestamp\n",
    "\n",
    "def train_test_result(dir, stock, variable, window_size, start_date, end_date):\n",
    "    #score data 뽑기\n",
    "    score = pd.read_csv(dir)\n",
    "    score.columns = [\"Date\", \"N_Score\", \"B_Score\"]\n",
    "    \n",
    "    end_1_next_date = pd.to_datetime(end_date, errors=\"ignore\") + datetime.timedelta(days=1)\n",
    "    end_1_next_date = end_1_next_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    #price data 뽑기\n",
    "    price_data = yf.download([stock],start = start_date, end = end_1_next_date)\n",
    "    \n",
    "    opening = price_data.index.copy()\n",
    "    opening = pd.DataFrame(opening)\n",
    "    opening[\"opening_date\"] = 1\n",
    "    opening.Date = opening.Date.apply(lambda x: date_cut_day(x))\n",
    "    \n",
    "    start_2_previous_date = pd.to_datetime(start_date, errors=\"ignore\") - datetime.timedelta(days=2)\n",
    "    start_2_previous_date = start_2_previous_date.strftime('%Y%m%d')\n",
    "    \n",
    "    Date = pd.date_range(start=start_2_previous_date, end=pd.to_datetime(end_date).strftime('%Y%m%d'))\n",
    "    Date = pd.DataFrame({\"Date\" : Date.values})\n",
    "    Date.Date = Date.Date.apply(lambda x: date_cut_day(x))\n",
    "\n",
    "    \n",
    "    set_news_data_date = pd.merge(Date, opening, how =\"left\",left_on='Date', right_on = \"Date\") \n",
    "    set_news_data_date = set_news_data_date.where(pd.notnull(set_news_data_date), 0) \n",
    "    set_news_data_date.Date = set_news_data_date.Date.apply(lambda x: pd.to_datetime(x, errors=\"ignore\"))\n",
    "\n",
    "    standard=set_news_data_date.Date.iloc[len(set_news_data_date)-1] + datetime.timedelta(days=1)\n",
    "    set_news_data_date[\"price_date\"]=0\n",
    "    for i in range(len(set_news_data_date)-1,-1,-1):\n",
    "        if i==(len(set_news_data_date)-1):\n",
    "            standard = set_news_data_date.Date[i]\n",
    "            set_news_data_date.price_date[i]=standard  + datetime.timedelta(days=1)\n",
    "        elif (set_news_data_date.opening_date[i]==1)&(set_news_data_date.opening_date[i+1]==1):\n",
    "            standard = set_news_data_date.Date[i]\n",
    "            set_news_data_date.price_date[i]=standard  + datetime.timedelta(days=1)\n",
    "        elif (i!=0):\n",
    "            if((set_news_data_date.opening_date[i]==1)&(set_news_data_date.opening_date[i+1]==0)&(set_news_data_date.opening_date[i-1]==0)):\n",
    "                set_news_data_date.price_date[i]=standard  + datetime.timedelta(days=1)\n",
    "                standard = set_news_data_date.Date[i]\n",
    "            else:\n",
    "                set_news_data_date.price_date[i]=standard\n",
    "        else:\n",
    "            set_news_data_date.price_date[i]=standard\n",
    "    \n",
    "    set_news_data_date.Date = set_news_data_date.Date.apply(lambda x: date_cut_day(x))\n",
    "    \n",
    "    score = pd.merge(set_news_data_date,score, how =\"left\",on = \"Date\")\n",
    "    \n",
    "    score = score[['Date','N_Score', \"B_Score\", \"price_date\"]]\n",
    "    score = score.groupby('price_date').mean({\"N_Score\", \"B_Score\"})\n",
    "    end_1_previous_date = pd.to_datetime(end_date, errors=\"ignore\") - datetime.timedelta(days=1)\n",
    "    end_1_previous_date = end_1_previous_date.strftime('%Y-%m-%d')\n",
    "    score = score[score.index<=end_1_previous_date]\n",
    "\n",
    "    start_2_previous_date = pd.to_datetime(start_date, errors=\"ignore\") - datetime.timedelta(days=2)\n",
    "    start_2_previous_date = start_2_previous_date.strftime('%Y-%m-%d')\n",
    "    first_data = yf.download([stock],start = start_2_previous_date, end = start_date)\n",
    "    \n",
    "    price_data = price_data.reset_index()\n",
    "    score = score.reset_index()\n",
    "    score.columns = [\"Date\", \"N_Score\", \"B_Score\"]\n",
    "    \n",
    "    #price data와 score data 결합\n",
    "    price_data = pd.merge(price_data, score, how =\"left\",left_on='Date', right_on = \"Date\")[[\"Close\",\"Open\", \"High\" , \"Low\", \"Volume\" ,\"N_Score\", \"B_Score\"]]\n",
    "\n",
    "    #뉴스가 없는 날은 즉, score가 없는 날은 중립의 의미로 0으로 처리\n",
    "    price_data.N_Score[price_data.N_Score.isnull()]=0\n",
    "    price_data.B_Score[price_data.B_Score.isnull()]=0\n",
    "\n",
    "    #전날 종가의 영향을 받으므로 전날 종가 변수를 생성\n",
    "    price_data[\"before_close\"] = 0\n",
    "    price_data = price_data.reset_index(drop=True)\n",
    "    for i in range(len(price_data)-1):\n",
    "        price_data.before_close[i+1] = price_data.Close[i]\n",
    "    \n",
    "    price_data.before_close[0] = first_data[\"Close\"][0]\n",
    "\n",
    "    # minmaxscaler 사용\n",
    "    price_data.columns = [\"Close\",\"Open\", \"High\" , \"Low\", \"Volume\" ,\"N_Score\", \"B_Score\",\"before_close\"]\n",
    "    \n",
    "    x = price_data[variable]\n",
    "    y = price_data[[\"Close\"]]\n",
    "    scaler_x = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "\n",
    "    x = pd.DataFrame(scaler_x.fit_transform(x))\n",
    "    y = pd.DataFrame(scaler_y.fit_transform(y))\n",
    "    \n",
    "    x.columns = variable\n",
    "    y.columns = [\"Close\"]\n",
    "\n",
    "    train_index = int(len(x)*0.8)\n",
    "\n",
    "    train_x = x.iloc[0:train_index]\n",
    "    test_x = x.iloc[train_index:len(x)]\n",
    "\n",
    "    train_y = y.iloc[0:train_index]\n",
    "    test_y = y.iloc[train_index:len(y)]\n",
    "\n",
    "    train_x = train_x.to_numpy().reshape(train_x.shape[0],1,train_x.shape[1])\n",
    "    train_y = train_y.to_numpy().reshape(train_y.shape[0],train_y.shape[1])\n",
    "    test_x = test_x.to_numpy().reshape(test_x.shape[0],1,test_x.shape[1])\n",
    "    test_y = test_y.to_numpy().reshape(test_y.shape[0],test_y.shape[1])\n",
    "    \n",
    "    #window size에 맞게 데이터 설정\n",
    "    x = np.zeros(shape=(train_x.shape[0]-window_size+1,window_size,x.shape[1]))\n",
    "    for i in range(train_x.shape[0]-window_size+1):\n",
    "        x[i]=np.vstack((train_x[i:i+window_size]))\n",
    "\n",
    "    y = train_y[window_size-1:train_x.shape[0]]\n",
    "\n",
    "    x_t = np.zeros(shape=(test_x.shape[0]-window_size+1,window_size,x.shape[2]))\n",
    "    for i in range(test_x.shape[0]-window_size+1):\n",
    "        x_t[i]=np.vstack((test_x[i:i+window_size]))\n",
    "    \n",
    "    y_t = test_y[window_size-1:test_x.shape[0]]\n",
    "    \n",
    "    return scaler_x, scaler_y, x, y, x_t, y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aac7093-06f6-440f-bd6f-613dd3cc1690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2758964/4182547383.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  set_news_data_date.price_date[i]=standard  + datetime.timedelta(days=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2758964/4182547383.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price_data.before_close[i+1] = price_data.Close[i]\n"
     ]
    }
   ],
   "source": [
    "dir = \"nyt_score.csv\"\n",
    "stock = \"AMZN\"\n",
    "variable = [\"Open\",\"High\",\"Low\",\"Volume\",\"N_Score\", \"B_Score\"]\n",
    "window_size = 1\n",
    "start_date = \"2015-01-01\"\n",
    "end_date = \"2020-08-13\"\n",
    "\n",
    "scaler_x, scaler_y, x, y, x_t, y_t = train_test_result(dir, stock, variable, window_size, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0d19ba0-c66d-4b77-b2fd-228d2e7ec54a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 15:00:11.660138: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-24 15:00:11.660266: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-24 15:00:11.660348: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-24 15:00:11.660427: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-04-24 15:00:11.693961: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-24 15:00:11.694022: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-04-24 15:00:11.694036: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-04-24 15:00:11.695045: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "8/8 [==============================] - 3s 97ms/step - loss: 0.0466 - mae: 0.1743 - val_loss: 0.2056 - val_mae: 0.4508\n",
      "Epoch 2/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0319 - mae: 0.1345 - val_loss: 0.1567 - val_mae: 0.3928\n",
      "Epoch 3/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0207 - mae: 0.1049 - val_loss: 0.1089 - val_mae: 0.3263\n",
      "Epoch 4/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0143 - mae: 0.0914 - val_loss: 0.0692 - val_mae: 0.2584\n",
      "Epoch 5/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0130 - mae: 0.0940 - val_loss: 0.0526 - val_mae: 0.2244\n",
      "Epoch 6/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0120 - mae: 0.0911 - val_loss: 0.0526 - val_mae: 0.2250\n",
      "Epoch 7/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0103 - mae: 0.0826 - val_loss: 0.0523 - val_mae: 0.2250\n",
      "Epoch 8/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0088 - mae: 0.0753 - val_loss: 0.0423 - val_mae: 0.2021\n",
      "Epoch 9/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0072 - mae: 0.0690 - val_loss: 0.0296 - val_mae: 0.1686\n",
      "Epoch 10/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0055 - mae: 0.0607 - val_loss: 0.0213 - val_mae: 0.1430\n",
      "Epoch 11/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0038 - mae: 0.0502 - val_loss: 0.0138 - val_mae: 0.1151\n",
      "Epoch 12/40\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0023 - mae: 0.0386 - val_loss: 0.0071 - val_mae: 0.0824\n",
      "Epoch 13/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0012 - mae: 0.0279 - val_loss: 0.0017 - val_mae: 0.0391\n",
      "Epoch 14/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.2630e-04 - mae: 0.0165 - val_loss: 6.6349e-04 - val_mae: 0.0241\n",
      "Epoch 15/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.3524e-04 - mae: 0.0096 - val_loss: 9.2198e-05 - val_mae: 0.0068\n",
      "Epoch 16/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 7.2037e-05 - mae: 0.0064 - val_loss: 2.9545e-04 - val_mae: 0.0146\n",
      "Epoch 17/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7.2979e-05 - mae: 0.0065 - val_loss: 2.1166e-04 - val_mae: 0.0119\n",
      "Epoch 18/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7.0385e-05 - mae: 0.0066 - val_loss: 2.5698e-04 - val_mae: 0.0136\n",
      "Epoch 19/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 6.0321e-05 - mae: 0.0058 - val_loss: 1.4302e-04 - val_mae: 0.0092\n",
      "Epoch 20/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.9511e-05 - mae: 0.0055 - val_loss: 9.6285e-05 - val_mae: 0.0070\n",
      "Epoch 21/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.6387e-05 - mae: 0.0051 - val_loss: 9.3496e-05 - val_mae: 0.0069\n",
      "Epoch 22/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.3891e-05 - mae: 0.0052 - val_loss: 6.8828e-05 - val_mae: 0.0058\n",
      "Epoch 23/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.3333e-05 - mae: 0.0050 - val_loss: 8.0821e-05 - val_mae: 0.0064\n",
      "Epoch 24/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.9602e-05 - mae: 0.0049 - val_loss: 6.5977e-05 - val_mae: 0.0058\n",
      "Epoch 25/40\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 3.8706e-05 - mae: 0.0049 - val_loss: 7.6868e-05 - val_mae: 0.0063\n",
      "Epoch 26/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.6978e-05 - mae: 0.0047 - val_loss: 7.3549e-05 - val_mae: 0.0062\n",
      "Epoch 27/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.6282e-05 - mae: 0.0048 - val_loss: 7.9797e-05 - val_mae: 0.0065\n",
      "Epoch 28/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.5839e-05 - mae: 0.0045 - val_loss: 8.6594e-05 - val_mae: 0.0069\n",
      "Epoch 29/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.4288e-05 - mae: 0.0045 - val_loss: 7.3339e-05 - val_mae: 0.0062\n",
      "Epoch 30/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.3075e-05 - mae: 0.0044 - val_loss: 7.6490e-05 - val_mae: 0.0064\n",
      "Epoch 31/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.1916e-05 - mae: 0.0043 - val_loss: 6.8906e-05 - val_mae: 0.0061\n",
      "Epoch 32/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.1319e-05 - mae: 0.0044 - val_loss: 7.0114e-05 - val_mae: 0.0061\n",
      "Epoch 33/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.0696e-05 - mae: 0.0042 - val_loss: 7.1136e-05 - val_mae: 0.0062\n",
      "Epoch 34/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.9994e-05 - mae: 0.0041 - val_loss: 6.7191e-05 - val_mae: 0.0060\n",
      "Epoch 35/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.9177e-05 - mae: 0.0042 - val_loss: 6.8817e-05 - val_mae: 0.0061\n",
      "Epoch 36/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.8523e-05 - mae: 0.0041 - val_loss: 6.8409e-05 - val_mae: 0.0061\n",
      "Epoch 37/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.7985e-05 - mae: 0.0040 - val_loss: 6.9548e-05 - val_mae: 0.0062\n",
      "Epoch 38/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.7372e-05 - mae: 0.0039 - val_loss: 7.0062e-05 - val_mae: 0.0062\n",
      "Epoch 39/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.6959e-05 - mae: 0.0039 - val_loss: 7.3451e-05 - val_mae: 0.0064\n",
      "Epoch 40/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.6670e-05 - mae: 0.0039 - val_loss: 7.7561e-05 - val_mae: 0.0066\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.001842974335886538, 0.02323918230831623]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_1_model = Sequential()\n",
    "lstm_1_model.add(LSTM(50, input_shape = (x.shape[1],x.shape[2]),return_sequences=True))\n",
    "lstm_1_model.add((LSTM(50)))\n",
    "lstm_1_model.add(Dense(1,activation=\"tanh\"))\n",
    "lstm_1_model.compile(optimizer=\"adam\", loss = 'mse' , metrics=[\"mae\"])\n",
    "history = lstm_1_model.fit(x, y, epochs=40, batch_size=128, validation_split=0.2)\n",
    "    \n",
    "lstm_1_model.evaluate(x_t, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a40b07b-6b7f-4997-9094-01d4270ad552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.001842974335886538, 0.02323918230831623]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_1_model.evaluate(x_t, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a4f00ca-21ee-4daa-969d-030f29ba2521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float64, numpy=6.306505209145918>,\n",
       " 39.772007952984595,\n",
       " 3.4138929549038615,\n",
       " 2.594839723514224)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_1_pred = lstm_1_model.predict(x_t)\n",
    "lstm_1_pred = scaler_y.inverse_transform(lstm_1_pred)\n",
    "y_t = scaler_y.inverse_transform(y_t)\n",
    "root_mean_squared_error(y_t, lstm_1_pred), mean_squared_error(y_t, lstm_1_pred), mean_absolute_error(y_t, lstm_1_pred), MAPE(y_t, lstm_1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcede207-d7b6-447c-97df-fee29fba75f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### 논문 재현 DowJ ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "552142df-d77b-4a4c-b4f7-67ef42f02363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2758964/4182547383.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  set_news_data_date.price_date[i]=standard  + datetime.timedelta(days=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2758964/4182547383.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price_data.before_close[i+1] = price_data.Close[i]\n"
     ]
    }
   ],
   "source": [
    "dir = \"nyt_score.csv\"\n",
    "stock = \"^DJI\"\n",
    "variable = [\"Open\",\"High\",\"Low\",\"Volume\",\"N_Score\", \"B_Score\"]\n",
    "window_size = 1\n",
    "start_date = \"2015-01-01\"\n",
    "end_date = \"2020-08-13\"\n",
    "\n",
    "scaler_x, scaler_y, x, y, x_t, y_t = train_test_result(dir, stock, variable, window_size, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e20b49b2-f41d-4830-8b96-bfd7a9737721",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "8/8 [==============================] - 3s 82ms/step - loss: 0.1285 - mae: 0.2944 - val_loss: 0.4210 - val_mae: 0.6456\n",
      "Epoch 2/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1010 - mae: 0.2506 - val_loss: 0.3415 - val_mae: 0.5809\n",
      "Epoch 3/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0733 - mae: 0.2020 - val_loss: 0.2518 - val_mae: 0.4980\n",
      "Epoch 4/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0462 - mae: 0.1525 - val_loss: 0.1546 - val_mae: 0.3887\n",
      "Epoch 5/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0261 - mae: 0.1299 - val_loss: 0.0761 - val_mae: 0.2699\n",
      "Epoch 6/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0196 - mae: 0.1250 - val_loss: 0.0396 - val_mae: 0.1918\n",
      "Epoch 7/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0185 - mae: 0.1229 - val_loss: 0.0339 - val_mae: 0.1773\n",
      "Epoch 8/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0150 - mae: 0.1103 - val_loss: 0.0380 - val_mae: 0.1890\n",
      "Epoch 9/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0117 - mae: 0.0959 - val_loss: 0.0370 - val_mae: 0.1869\n",
      "Epoch 10/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0091 - mae: 0.0833 - val_loss: 0.0270 - val_mae: 0.1590\n",
      "Epoch 11/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0065 - mae: 0.0706 - val_loss: 0.0175 - val_mae: 0.1267\n",
      "Epoch 12/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0579 - val_loss: 0.0116 - val_mae: 0.1021\n",
      "Epoch 13/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0028 - mae: 0.0449 - val_loss: 0.0077 - val_mae: 0.0820\n",
      "Epoch 14/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0016 - mae: 0.0325 - val_loss: 0.0058 - val_mae: 0.0708\n",
      "Epoch 15/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 9.4259e-04 - mae: 0.0230 - val_loss: 0.0038 - val_mae: 0.0565\n",
      "Epoch 16/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 6.4954e-04 - mae: 0.0186 - val_loss: 0.0025 - val_mae: 0.0445\n",
      "Epoch 17/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.4017e-04 - mae: 0.0173 - val_loss: 0.0022 - val_mae: 0.0414\n",
      "Epoch 18/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.1316e-04 - mae: 0.0172 - val_loss: 0.0018 - val_mae: 0.0368\n",
      "Epoch 19/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.9606e-04 - mae: 0.0168 - val_loss: 0.0017 - val_mae: 0.0353\n",
      "Epoch 20/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.7786e-04 - mae: 0.0166 - val_loss: 0.0018 - val_mae: 0.0369\n",
      "Epoch 21/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.6253e-04 - mae: 0.0166 - val_loss: 0.0018 - val_mae: 0.0369\n",
      "Epoch 22/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.4089e-04 - mae: 0.0160 - val_loss: 0.0016 - val_mae: 0.0345\n",
      "Epoch 23/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.2354e-04 - mae: 0.0155 - val_loss: 0.0016 - val_mae: 0.0344\n",
      "Epoch 24/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.0423e-04 - mae: 0.0153 - val_loss: 0.0017 - val_mae: 0.0362\n",
      "Epoch 25/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.9371e-04 - mae: 0.0153 - val_loss: 0.0016 - val_mae: 0.0351\n",
      "Epoch 26/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.6967e-04 - mae: 0.0144 - val_loss: 0.0013 - val_mae: 0.0307\n",
      "Epoch 27/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.5996e-04 - mae: 0.0140 - val_loss: 0.0014 - val_mae: 0.0322\n",
      "Epoch 28/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.3867e-04 - mae: 0.0138 - val_loss: 0.0014 - val_mae: 0.0332\n",
      "Epoch 29/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.2539e-04 - mae: 0.0136 - val_loss: 0.0013 - val_mae: 0.0321\n",
      "Epoch 30/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.1184e-04 - mae: 0.0134 - val_loss: 0.0013 - val_mae: 0.0319\n",
      "Epoch 31/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.0128e-04 - mae: 0.0132 - val_loss: 0.0012 - val_mae: 0.0311\n",
      "Epoch 32/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.8516e-04 - mae: 0.0125 - val_loss: 0.0010 - val_mae: 0.0278\n",
      "Epoch 33/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.7583e-04 - mae: 0.0122 - val_loss: 0.0011 - val_mae: 0.0295\n",
      "Epoch 34/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.6483e-04 - mae: 0.0123 - val_loss: 0.0011 - val_mae: 0.0296\n",
      "Epoch 35/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.5029e-04 - mae: 0.0118 - val_loss: 8.8343e-04 - val_mae: 0.0257\n",
      "Epoch 36/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.4125e-04 - mae: 0.0114 - val_loss: 9.0602e-04 - val_mae: 0.0263\n",
      "Epoch 37/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.2900e-04 - mae: 0.0112 - val_loss: 8.6540e-04 - val_mae: 0.0257\n",
      "Epoch 38/40\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.1928e-04 - mae: 0.0109 - val_loss: 8.3191e-04 - val_mae: 0.0252\n",
      "Epoch 39/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.1003e-04 - mae: 0.0107 - val_loss: 8.6926e-04 - val_mae: 0.0260\n",
      "Epoch 40/40\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.0387e-04 - mae: 0.0107 - val_loss: 7.8807e-04 - val_mae: 0.0247\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.003818240249529481, 0.05162724480032921]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_1_model = Sequential()\n",
    "lstm_1_model.add(LSTM(50, input_shape = (x.shape[1],x.shape[2]),return_sequences=True))\n",
    "lstm_1_model.add((LSTM(50)))\n",
    "lstm_1_model.add(Dense(1,activation=\"tanh\"))\n",
    "lstm_1_model.compile(optimizer=\"adam\", loss = 'mse' , metrics=[\"mae\"])\n",
    "history = lstm_1_model.fit(x, y, epochs=40, batch_size=128, validation_split=0.2)\n",
    "    \n",
    "lstm_1_model.evaluate(x_t, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd825ece-0453-4fc5-84aa-d706b25642f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.003818240249529481, 0.05162724480032921]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_1_model.evaluate(x_t, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91a66885-9847-4cab-ad55-f90a72e54868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float64, numpy=858.366089725644>,\n",
       " 736792.3439908923,\n",
       " 717.166195064046,\n",
       " 2.6650830226510496)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_1_pred = lstm_1_model.predict(x_t)\n",
    "lstm_1_pred = scaler_y.inverse_transform(lstm_1_pred)\n",
    "y_t = scaler_y.inverse_transform(y_t)\n",
    "root_mean_squared_error(y_t, lstm_1_pred), mean_squared_error(y_t, lstm_1_pred), mean_absolute_error(y_t, lstm_1_pred), MAPE(y_t, lstm_1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89616736-5554-4e19-97b9-e06ffcbaf2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### 2 variable(news, close 사용) #####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9640f9d5-5cbd-4cf7-b4d2-dc795adb37f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whfhrs3260/Python/10year_data/review/train_test.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  set_news_data_date.price_date[i]=standard  + datetime.timedelta(days=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whfhrs3260/Python/10year_data/review/train_test.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price_data.before_close[i+1] = price_data.Close[i]\n"
     ]
    }
   ],
   "source": [
    "dir = \"/home/whfhrs3260/csv_data/price_data_score_10years.csv\"\n",
    "stock = \"^DJI\"\n",
    "variable = [\"before_close\",\"Score\"]\n",
    "window_size = 1\n",
    "start_date = \"2015-01-01\"\n",
    "end_date = \"2020-08-13\"\n",
    "\n",
    "scaler_x, scaler_y, x, y, x_t, y_t = tt.train_test_result(dir, stock, variable, window_size, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a514b859-6c18-490c-86b1-01b654d8f78b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "7/7 [==============================] - 3s 99ms/step - loss: 0.0941 - mae: 0.2506 - val_loss: 0.4047 - val_mae: 0.6340\n",
      "Epoch 2/40\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0744 - mae: 0.2116 - val_loss: 0.3441 - val_mae: 0.5843\n",
      "Epoch 3/40\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0564 - mae: 0.1733 - val_loss: 0.2805 - val_mae: 0.5270\n",
      "Epoch 4/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0406 - mae: 0.1367 - val_loss: 0.2143 - val_mae: 0.4598\n",
      "Epoch 5/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0295 - mae: 0.1251 - val_loss: 0.1539 - val_mae: 0.3886\n",
      "Epoch 6/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0251 - mae: 0.1310 - val_loss: 0.1142 - val_mae: 0.3335\n",
      "Epoch 7/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0243 - mae: 0.1344 - val_loss: 0.1032 - val_mae: 0.3167\n",
      "Epoch 8/40\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0233 - mae: 0.1316 - val_loss: 0.1041 - val_mae: 0.3185\n",
      "Epoch 9/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0217 - mae: 0.1261 - val_loss: 0.1017 - val_mae: 0.3149\n",
      "Epoch 10/40\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0203 - mae: 0.1207 - val_loss: 0.1002 - val_mae: 0.3126\n",
      "Epoch 11/40\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0189 - mae: 0.1160 - val_loss: 0.0908 - val_mae: 0.2975\n",
      "Epoch 12/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0175 - mae: 0.1118 - val_loss: 0.0826 - val_mae: 0.2837\n",
      "Epoch 13/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0160 - mae: 0.1071 - val_loss: 0.0744 - val_mae: 0.2692\n",
      "Epoch 14/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0145 - mae: 0.1018 - val_loss: 0.0657 - val_mae: 0.2526\n",
      "Epoch 15/40\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0129 - mae: 0.0963 - val_loss: 0.0560 - val_mae: 0.2329\n",
      "Epoch 16/40\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0111 - mae: 0.0891 - val_loss: 0.0511 - val_mae: 0.2226\n",
      "Epoch 17/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0094 - mae: 0.0805 - val_loss: 0.0445 - val_mae: 0.2077\n",
      "Epoch 18/40\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0077 - mae: 0.0724 - val_loss: 0.0336 - val_mae: 0.1798\n",
      "Epoch 19/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0061 - mae: 0.0652 - val_loss: 0.0235 - val_mae: 0.1495\n",
      "Epoch 20/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0046 - mae: 0.0559 - val_loss: 0.0194 - val_mae: 0.1358\n",
      "Epoch 21/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0033 - mae: 0.0451 - val_loss: 0.0145 - val_mae: 0.1167\n",
      "Epoch 22/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0022 - mae: 0.0370 - val_loss: 0.0077 - val_mae: 0.0831\n",
      "Epoch 23/40\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0014 - mae: 0.0292 - val_loss: 0.0055 - val_mae: 0.0692\n",
      "Epoch 24/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 8.4616e-04 - mae: 0.0210 - val_loss: 0.0036 - val_mae: 0.0543\n",
      "Epoch 25/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 5.0687e-04 - mae: 0.0163 - val_loss: 0.0017 - val_mae: 0.0356\n",
      "Epoch 26/40\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 3.2994e-04 - mae: 0.0136 - val_loss: 0.0013 - val_mae: 0.0300\n",
      "Epoch 27/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2.3983e-04 - mae: 0.0115 - val_loss: 9.0956e-04 - val_mae: 0.0248\n",
      "Epoch 28/40\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2.0757e-04 - mae: 0.0109 - val_loss: 6.9056e-04 - val_mae: 0.0212\n",
      "Epoch 29/40\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.9341e-04 - mae: 0.0106 - val_loss: 6.3542e-04 - val_mae: 0.0203\n",
      "Epoch 30/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.8617e-04 - mae: 0.0104 - val_loss: 5.7874e-04 - val_mae: 0.0192\n",
      "Epoch 31/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.8114e-04 - mae: 0.0102 - val_loss: 5.6775e-04 - val_mae: 0.0190\n",
      "Epoch 32/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.7533e-04 - mae: 0.0101 - val_loss: 5.5523e-04 - val_mae: 0.0188\n",
      "Epoch 33/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.7051e-04 - mae: 0.0099 - val_loss: 5.4291e-04 - val_mae: 0.0185\n",
      "Epoch 34/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.6420e-04 - mae: 0.0097 - val_loss: 5.5936e-04 - val_mae: 0.0189\n",
      "Epoch 35/40\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.6064e-04 - mae: 0.0095 - val_loss: 5.4123e-04 - val_mae: 0.0185\n",
      "Epoch 36/40\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.5470e-04 - mae: 0.0092 - val_loss: 5.6489e-04 - val_mae: 0.0190\n",
      "Epoch 37/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.5204e-04 - mae: 0.0091 - val_loss: 5.4125e-04 - val_mae: 0.0185\n",
      "Epoch 38/40\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.4878e-04 - mae: 0.0090 - val_loss: 5.5407e-04 - val_mae: 0.0188\n",
      "Epoch 39/40\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.4592e-04 - mae: 0.0088 - val_loss: 5.2872e-04 - val_mae: 0.0183\n",
      "Epoch 40/40\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.4310e-04 - mae: 0.0087 - val_loss: 5.4689e-04 - val_mae: 0.0187\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.003308473387733102, 0.04681278020143509]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_1_model = Sequential()\n",
    "lstm_1_model.add(LSTM(50, input_shape = (x.shape[1],x.shape[2]),return_sequences=True))\n",
    "lstm_1_model.add((LSTM(50)))\n",
    "lstm_1_model.add(Dense(1,activation=\"tanh\"))\n",
    "lstm_1_model.compile(optimizer=\"adam\", loss = 'mse' , metrics=[\"mae\"])\n",
    "history = lstm_1_model.fit(x, y, epochs=40, batch_size=128, validation_split=0.2)\n",
    "    \n",
    "lstm_1_model.evaluate(x_t, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96511271-71c9-41a6-a029-8daf077686cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.003308473387733102, 0.04681278020143509]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_1_model.evaluate(x_t, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cbe5e11-7305-4ea9-bd0d-2e391198c416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float64, numpy=799.0145507663063>,\n",
       " 638424.2523362823,\n",
       " 650.2872426470589,\n",
       " 2.465812723214691)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_1_pred = lstm_1_model.predict(x_t)\n",
    "lstm_1_pred = scaler_y.inverse_transform(lstm_1_pred)\n",
    "y_t = scaler_y.inverse_transform(y_t)\n",
    "root_mean_squared_error(y_t, lstm_1_pred), mean_squared_error(y_t, lstm_1_pred), mean_absolute_error(y_t, lstm_1_pred), MAPE(y_t, lstm_1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934309b7-71b9-4706-9983-72f252b6907a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
